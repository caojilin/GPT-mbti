{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import concurrent.futures\n",
    "from collections import Counter\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=\"sk-dP3OLsFmsPb2kgfFaeYO5im3fx9KZkLtVBsMwRqMwvzsdQtI\",\n",
    "    base_url=\"https://api.chatanywhere.tech/v1\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbti_types = [\n",
    "    \"INTJ\", \"INTP\", \"ENTJ\", \"ENTP\", \n",
    "    \"INFJ\", \"INFP\", \"ENFJ\", \"ENFP\", \n",
    "    \"ISTJ\", \"ISFJ\", \"ESTJ\", \"ESFJ\", \n",
    "    \"ISTP\", \"ISFP\", \"ESTP\", \"ESFP\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"At a party do you:\"\n",
    "options =  [\n",
    "            \"Interact with many, including strangers\",\n",
    "            \"Interact with a few, known to you\"\n",
    "        ]\n",
    "name = \"Pam Beasley\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Now we are conducting a MBTI test. questions will be given to you one by one.\n",
    "Each question has two options that you can choose from.\n",
    "Imagine you are {name} from the office.\n",
    "question: {question}\n",
    "option1: {options[0]}\n",
    "option2: {options[1]}\n",
    "you should give me a single number as answer. If you choose the first option, give me 1, if you choose second option, give me 2.\n",
    "It's very important that you give me only a number.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 1882.42it/s]\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "weights = []\n",
    "name = \"Zeke Yeager\"\n",
    "show_name = \"Attack On Titans\"\n",
    "def make_api_call(entry):\n",
    "    # Simulate an API call that takes some time\n",
    "    question = entry['question']\n",
    "    options = entry['options']\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are {name} from the {show_name}. you should think like {name} based on the {name}'s personality and chracteristics.\n",
    "    questions will be given to you one by one.\n",
    "    Each question has two options that you can choose from.\n",
    "    question: {question}\n",
    "    option1: {options[0]}\n",
    "    option2: {options[1]}\n",
    "    you should give me a single number as answer. If you choose the first option, give me 1, if you choose second option, give me 2.\n",
    "    It's very important that you give me only a number.\n",
    "    \"\"\"\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    answers.append(response)\n",
    "    weights.append(entry['weights'])\n",
    "    return response\n",
    "\n",
    "\n",
    "# Create a thread pool with a maximum of 5 concurrent threads\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:\n",
    "    # Submit each API call as a separate task\n",
    "    futures = [executor.submit(make_api_call, entry) for entry in tqdm.tqdm(data)]\n",
    "\n",
    "    # Wait for all tasks to complete and collect results\n",
    "    results = [future.result() for future in futures]\n",
    "\n",
    "current_time = datetime.datetime.now()\n",
    "# Format the time string without seconds and spaces for use as a file name\n",
    "formatted_time = current_time.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "cnt = Counter()\n",
    "for i in range(len(answers)):\n",
    "    try:\n",
    "        index = int(answers[i])\n",
    "    except ValueError as e:\n",
    "        if '1' in answers[i]:\n",
    "            index = 1\n",
    "        elif '2' in answers[i]:\n",
    "            index = 2\n",
    "        else:\n",
    "            index = 0\n",
    "    cnt[weights[i][index-1]] += 1\n",
    "\n",
    "(cnt['e'] + cnt['i']), (cnt['n'] + cnt['s']),(cnt['t'] + cnt['f']),(cnt['p'] + cnt['j'])\n",
    "\n",
    "energy_forcus = cnt['e']/(cnt['e'] + cnt['i'])\n",
    "info_processing = cnt['n']/(cnt['n'] + cnt['s'])\n",
    "decision_making = cnt['t']/(cnt['t'] + cnt['f'])\n",
    "lifestyle_preference = cnt['p']/(cnt['p'] + cnt['j'])\n",
    "\n",
    "result = {'E':energy_forcus, 'N': info_processing, 'T':decision_making, \"P\": lifestyle_preference}\n",
    "\n",
    "df = pd.DataFrame(columns=['answer', 'info'])\n",
    "df['answer'] = answers\n",
    "\n",
    "df.to_csv(f\"GPT4o-mini/{formatted_time}_{name}.csv\", index=False)  # index=False avoids saving the index column\n",
    "with open(f\"GPT4o-mini/{formatted_time}_{name}.json\", \"w\") as file:\n",
    "    json.dump(result, file, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
